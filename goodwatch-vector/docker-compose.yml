services:
  embeddings:
    build:
      context: ./embeddings
      dockerfile: Dockerfile
      args:
        HUGGING_FACE_HUB_TOKEN: ${HUGGING_FACE_HUB_TOKEN}
        EMBEDDING_MODEL_NAME: ${EMBEDDING_MODEL_NAME}
        LLM_MODEL_REPO_ID: ${LLM_MODEL_REPO_ID}
        LLM_MODEL_FILENAME: ${LLM_MODEL_FILENAME}
    ports:
      - "7997:80"
    restart: unless-stopped
    environment:
      - HUGGING_FACE_HUB_TOKEN=${HUGGING_FACE_HUB_TOKEN}
      - EMBEDDING_MODEL_NAME=${EMBEDDING_MODEL_NAME}
      - LLM_MODEL_REPO_ID=${LLM_MODEL_REPO_ID}
      - LLM_MODEL_FILENAME=${LLM_MODEL_FILENAME}
    volumes:
      - embeddings_cache:/app/.cache/huggingface
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "10"

volumes:
  embeddings_cache:
